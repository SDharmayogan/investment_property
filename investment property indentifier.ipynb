{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import metapy\n",
    "import sys\n",
    "import time\n",
    "import pytoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = metapy.index.make_inverted_index('config.toml')\n",
    "idx.num_docs()\n",
    "idx.unique_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fidx = metapy.index.make_forward_index('config.toml')\n",
    "fidx.num_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = metapy.classify.MulticlassDataset(fidx)\n",
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'investment', 'movein'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([dset.label(instance) for instance in dset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 vs 0\n"
     ]
    }
   ],
   "source": [
    "view = dset[0:len(dset)+1]\n",
    "view = metapy.classify.MulticlassDatasetView(dset)\n",
    "view.shuffle()\n",
    "print(\"{} vs {}\".format(view[0].id, dset[0].id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = view[0:int(0.75*len(view))]\n",
    "testing = view[int(0.75*len(view)):len(view)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = metapy.classify.NaiveBayes(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              investment  movein      \n",
      "            ------------------------\n",
      " investment | \u001b[1m1\u001b[22m           -           \n",
      "     movein | 0.5         \u001b[1m0.5\u001b[22m         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtrx = nb.test(testing)\n",
    "print(mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
      "------------------------------------------------------------\n",
      "investment  0.857       0.75        1           0.6         \n",
      "movein      0.667       1           0.5         0.4         \n",
      "------------------------------------------------------------\n",
      "\u001b[1mTotal\u001b[22m       \u001b[1m0.824\u001b[22m       \u001b[1m0.85\u001b[22m        \u001b[1m0.8\u001b[22m         \n",
      "------------------------------------------------------------\n",
      "5 predictions attempted, overall accuracy: 0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtrx.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.10526275634766"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.num_docs()\n",
    "idx.avg_doc_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1693"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.total_corpus_terms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential scope refurbishment value stamp modernisation improvement need convert future\n",
      "[(6, 5.730287551879883), (3, 5.7234954833984375), (0, 3.951308250427246), (4, 3.904705762863159), (5, 3.5449962615966797), (1, 2.516573190689087), (9, 2.180393695831299), (2, 2.0118000507354736), (7, 1.9803178310394287), (15, 1.8454886674880981)]\n",
      "10\n",
      "Query 1 average precision: 0.7004365079365078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7004365079365078"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = metapy.index.Document()\n",
    "ranker = metapy.index.OkapiBM25(k1=1.2,b=0.75,k3=500)\n",
    "num_results = 10\n",
    "ev = metapy.index.IREval('config.toml')\n",
    "with open('config.toml', 'r') as fin:\n",
    "        cfg_d = pytoml.load(fin)\n",
    "        \n",
    "query_cfg = cfg_d['query-runner']\n",
    "query_start = query_cfg.get('query-id-start', 0)\n",
    "    \n",
    "with open('investment-queries.txt') as query_file:\n",
    "    for query_num, line in enumerate(query_file):\n",
    "        query.content(line.strip())\n",
    "        print(query.content())\n",
    "        results = ranker.score(idx, query, num_results)\n",
    "        print(results)\n",
    "        print(num_results)\n",
    "        avg_p = ev.avg_p(results, query_start + query_num, num_results)\n",
    "        print(\"Query {} average precision: {}\".format(query_num + 1, avg_p))\n",
    "ev.map()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
